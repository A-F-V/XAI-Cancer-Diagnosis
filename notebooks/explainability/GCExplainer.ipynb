{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GCExplainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "\n",
    "parent = os.path.dirname(os.path.dirname(os.getcwd()))\n",
    "if parent not in sys.path:\n",
    "    sys.path.append(parent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_settings = {'evaluate_model':False}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model & Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available:  True\n",
      "CUDA device count:  1\n",
      "309\n",
      "76\n"
     ]
    }
   ],
   "source": [
    "# Data\n",
    "\n",
    "from src.datasets.BACH import BACH\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.transforms import Compose, KNNGraph\n",
    "import torch\n",
    "graph_aug_val = Compose([KNNGraph(k=6)])\n",
    "\n",
    "\n",
    "print('CUDA available: ', torch.cuda.is_available())\n",
    "print('CUDA device count: ', torch.cuda.device_count())\n",
    "\n",
    "src_folder  = \"D:\\\\Documents\\\\git\\\\XAI-Cancer-Diagnosis\\\\XAI-Cancer-Diagnosis\\\\data\\\\processed\\\\BACH_TRAIN\"\n",
    "tid,vid = BACH.get_train_val_ids(src_folder)\n",
    "train_set = BACH(src_folder,graph_augmentation=graph_aug_val,ids=tid,pre_encoded=True)\n",
    "val_set = BACH(src_folder,graph_augmentation=graph_aug_val,ids=vid,pre_encoded=True)\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=1, shuffle=False)\n",
    "val_loader = DataLoader(val_set, batch_size=1, shuffle=False)\n",
    "\n",
    "print(len(train_loader))\n",
    "print(len(val_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CancerGNN(\n",
      "  (gnn): GCNx(\n",
      "    (conv): ModuleList(\n",
      "      (0): GCNConv(32, 32)\n",
      "      (1): GCNConv(32, 32)\n",
      "      (2): GCNConv(32, 32)\n",
      "      (3): GCNConv(32, 32)\n",
      "      (4): GCNConv(32, 32)\n",
      "      (5): GCNConv(32, 32)\n",
      "      (6): GCNConv(32, 32)\n",
      "    )\n",
      "    (transform): ModuleList(\n",
      "      (0): Sequential(\n",
      "        (0): BatchNorm1d(312, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (1): ReLU()\n",
      "        (2): Dropout(p=0.1, inplace=False)\n",
      "        (3): Linear(in_features=312, out_features=32, bias=True)\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): BatchNorm1d(32, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (1): ReLU()\n",
      "        (2): Dropout(p=0, inplace=False)\n",
      "        (3): Linear(in_features=32, out_features=32, bias=True)\n",
      "      )\n",
      "      (2): Sequential(\n",
      "        (0): BatchNorm1d(32, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (1): ReLU()\n",
      "        (2): Dropout(p=0, inplace=False)\n",
      "        (3): Linear(in_features=32, out_features=32, bias=True)\n",
      "      )\n",
      "      (3): Sequential(\n",
      "        (0): BatchNorm1d(32, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (1): ReLU()\n",
      "        (2): Dropout(p=0, inplace=False)\n",
      "        (3): Linear(in_features=32, out_features=32, bias=True)\n",
      "      )\n",
      "      (4): Sequential(\n",
      "        (0): BatchNorm1d(32, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (1): ReLU()\n",
      "        (2): Dropout(p=0, inplace=False)\n",
      "        (3): Linear(in_features=32, out_features=32, bias=True)\n",
      "      )\n",
      "      (5): Sequential(\n",
      "        (0): BatchNorm1d(32, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (1): ReLU()\n",
      "        (2): Dropout(p=0, inplace=False)\n",
      "        (3): Linear(in_features=32, out_features=32, bias=True)\n",
      "      )\n",
      "      (6): Sequential(\n",
      "        (0): BatchNorm1d(32, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (1): ReLU()\n",
      "        (2): Dropout(p=0, inplace=False)\n",
      "        (3): Linear(in_features=32, out_features=32, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (predictor): Sequential(\n",
      "    (0): Dropout(p=0.2, inplace=False)\n",
      "    (1): Linear(in_features=64, out_features=32, bias=True)\n",
      "    (2): BatchNorm1d(32, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
      "    (3): ReLU()\n",
      "    (4): Dropout(p=0, inplace=False)\n",
      "    (5): Linear(in_features=32, out_features=4, bias=True)\n",
      "  )\n",
      ")\n",
      "Sequential(\n",
      "  (0): Dropout(p=0.2, inplace=False)\n",
      "  (1): Linear(in_features=64, out_features=32, bias=True)\n",
      "  (2): BatchNorm1d(32, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
      "  (3): ReLU()\n",
      "  (4): Dropout(p=0, inplace=False)\n",
      "  (5): Linear(in_features=32, out_features=4, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "\n",
    "from src.deep_learning.architectures.cancer_prediction.cancer_gnn import CancerGNN\n",
    "\n",
    "model = CancerGNN.load_from_checkpoint(os.path.join(parent,\"model\", \"GCN.ckpt\"),WIDTH=32,HEIGHT=7)\n",
    "model.eval()\n",
    "model.requires_grad_(False)\n",
    "print(model)\n",
    "print(model.predictor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Dataset Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "def calculate_set_metric(loader,model,metric):\n",
    "    tot = 0\n",
    "    for batch in loader:\n",
    "        ans = model(batch.x,batch.edge_index,batch.batch)\n",
    "        tot += metric(ans,batch.y)\n",
    "    return tot/len(loader)\n",
    "\n",
    "def accuracy(ans,y):\n",
    "    y_hat = ans.argmax(dim=1)\n",
    "    return (y_hat == y).sum()\n",
    "\n",
    "def cancer_accuracy(ans,y):\n",
    "    y_hat = ans.argmax(dim=1)\n",
    "    return (y_hat <=1) ==(y<=1 ).sum()\n",
    "\n",
    "if notebook_settings['evaluate_model']:\n",
    "    print(\"Training Loss\",calculate_set_metric(train_loader,model,torch.nn.CrossEntropyLoss()))\n",
    "    print(\"Validation Loss\",calculate_set_metric(val_loader,model,torch.nn.CrossEntropyLoss()))\n",
    "    print(\"Training Accuracy\",calculate_set_metric(train_loader,model,accuracy))\n",
    "    print(\"Validation Accuracy\",calculate_set_metric(val_loader,model,accuracy))\n",
    "    print(\"Training Cancer Accuracy\",calculate_set_metric(train_loader,model,cancer_accuracy))\n",
    "    print(\"Validation Cancer Accuracy\",calculate_set_metric(val_loader,model,cancer_accuracy)) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.deep_learning.metrics.confusion_matrix import confusion_matrix\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "if notebook_settings['evaluate_model']:\n",
    "    pred, gt = [],[]\n",
    "    for graph in val_loader:\n",
    "        ans = model(graph.x,graph.edge_index,graph.batch)\n",
    "        pred.append(ans.argmax(dim=1).item()), gt.append(graph.y.item())\n",
    "        \n",
    "    f = plt.figure(figsize=(5,5))\n",
    "    ax = sns.heatmap(confusion_matrix(torch.tensor(gt),torch.tensor(pred),num_classes=4),annot=True, fmt=\".0f\",cbar=False,)\n",
    "    ax.set_xlabel(\"Predicted Class\")\n",
    "    ax.set_ylabel(\"True Class\")\n",
    "    ax.set_xticklabels([\"Normal\",\"Benign\",\"In Situ\",\"Invasive\"])\n",
    "    ax.set_yticklabels([\"Normal\",\"Benign\",\"In Situ\",\"Invasive\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Raw Activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Width:  32\n"
     ]
    }
   ],
   "source": [
    "model_width = model.width\n",
    "print(\"Model Width: \",model_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.hooks.RemovableHandle at 0x2c07371eee0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Attach the hook\n",
    "\n",
    "batch = next(iter(train_loader))\n",
    "raw_activations = torch.zeros(0,model_width)\n",
    "\n",
    "def append_raw_activations(self, input, output):\n",
    "    global raw_activations\n",
    "    raw_activations = torch.cat((raw_activations,output),dim=0)\n",
    "\n",
    "\n",
    "\n",
    "model.gnn.conv[-1].register_forward_hook(append_raw_activations)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|‚ñç         | 12/309 [00:04<01:52,  2.65it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14104/3896050008.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mground\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mnum_elems\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_elems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\aless\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tqdm\\std.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1180\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1181\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1182\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1183\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1184\u001b[0m                 \u001b[1;31m# Update and possibly print the progressbar.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\aless\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    519\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\aless\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    559\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 561\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    562\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\aless\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\aless\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Documents\\git\\XAI-Cancer-Diagnosis\\XAI-Cancer-Diagnosis\\src\\datasets\\BACH.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, ind)\u001b[0m\n\u001b[0;32m    201\u001b[0m             self.graph_dir if not self.pre_encoded else self.encoded_graph_dir, id_to_path(graph_id))\n\u001b[0;32m    202\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 203\u001b[1;33m         \u001b[0mgraph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    204\u001b[0m         \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_id\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph_augmentation\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\aless\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[0;32m    605\u001b[0m                     \u001b[0mopened_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morig_position\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    606\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 607\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    608\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_legacy_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\aless\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m_load\u001b[1;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[0;32m    880\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mUnpicklerWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    881\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 882\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_loaded_sparse_tensors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\aless\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mpersistent_load\u001b[1;34m(saved_id)\u001b[0m\n\u001b[0;32m    855\u001b[0m         \u001b[0mdata_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    856\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mloaded_storages\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 857\u001b[1;33m             \u001b[0mload_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_maybe_decode_ascii\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    858\u001b[0m         \u001b[0mstorage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloaded_storages\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    859\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mstorage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\aless\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mload_tensor\u001b[1;34m(data_type, size, key, location)\u001b[0m\n\u001b[0;32m    843\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    844\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 845\u001b[1;33m         \u001b[0mstorage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_storage_from_record\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    846\u001b[0m         \u001b[0mloaded_storages\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrestore_location\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    847\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Acquire the activations\n",
    "raw_activations = torch.zeros(0,model_width)\n",
    "predictions = torch.zeros(0)\n",
    "ground = torch.zeros(0)\n",
    "for batch in tqdm(train_loader):\n",
    "    num_elems = batch.x.shape[0]\n",
    "    predictions = torch.cat([predictions,torch.zeros(num_elems)+model(batch.x,batch.edge_index,batch.batch).argmax()])\n",
    "    ground = torch.cat([ground,(torch.zeros(num_elems)+batch.y)])\n",
    "\n",
    "predictions = torch.as_tensor(predictions)\n",
    "ground = torch.as_tensor(ground)\n",
    "#for batch in val_loader:\n",
    "#    model(batch.x,batch.edge_index,batch.batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([290887, 32])\n"
     ]
    }
   ],
   "source": [
    "print(raw_activations.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# K Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearest_mean(x,means):\n",
    "\n",
    "    delta = (means - x)**2\n",
    "    dists = delta.sum(axis=1)\n",
    "    return dists.argmin()\n",
    "\n",
    "def cluster(obs,means,k):\n",
    "    clusters = [[] for i in range(k)]\n",
    "    for i,x in enumerate(obs):\n",
    "        clusters[nearest_mean(x,means)].append(i)\n",
    "    return clusters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans,MiniBatchKMeans\n",
    "\n",
    "import numpy as np\n",
    "k_small = 6\n",
    "k_large = 32\n",
    "\n",
    "tsne_size = 10000\n",
    "\n",
    "obs = raw_activations.detach().numpy()\n",
    "mu,sigma = obs.mean(axis=0),obs.std(axis=0)\n",
    "\n",
    "print(len(obs))\n",
    "def whiten(obs):\n",
    "    return (obs - mu)/sigma\n",
    "\n",
    "obs_white = whiten(obs)\n",
    "means_small = MiniBatchKMeans(n_clusters= k_small).fit(obs_white).cluster_centers_\n",
    "means_large = MiniBatchKMeans(n_clusters=k_large).fit(obs_white).cluster_centers_\n",
    "\n",
    "\n",
    "\n",
    "np.random.seed(7)\n",
    "subset = np.random.choice(np.arange(len(obs)),size=tsne_size,replace=False)\n",
    "obs = obs[subset]\n",
    "obs_white = whiten(obs)\n",
    "\n",
    "clusters_small = cluster(obs_white,means_small,k_small)\n",
    "clusters_large = cluster(obs_white,means_large,k_large)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"mu.npy\",mu)\n",
    "np.save(\"sigma.npy\",sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Vizualize Explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'obs_white' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_21160/2956247373.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mTSNE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;34m'auto'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mperplexity\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m700\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobs_white\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;31m#reducer = PCA(n_components=2).fit(obs)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m#reducer = KernelPCA(n_components=2,kernel=\"rbf\",degree=2).fit(smaller_obs)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'obs_white' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "\n",
    "\n",
    "\n",
    "t =TSNE(n_components=2,learning_rate ='auto',verbose=2,perplexity = 1000,n_iter=700).fit_transform(obs_white)\n",
    "#reducer = PCA(n_components=2).fit(obs)\n",
    "#reducer = KernelPCA(n_components=2,kernel=\"rbf\",degree=2).fit(smaller_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "\n",
    "def plot_concept_clusters(cluster_ids,values):\n",
    "    f = plt.figure(figsize=(10,10))\n",
    "    plt.axis(\"off\")\n",
    "    colours = cm.rainbow(np.linspace(0,1,len(cluster_ids)))\n",
    "    for i,clust_ids in enumerate(cluster_ids):\n",
    "        v = values[clust_ids]\n",
    "        x,y = v[:,0],v[:,1]\n",
    "        plt.scatter(x,y,color=colours[i])\n",
    "    plt.show()\n",
    "\n",
    "def plot_cancer_clusters(cancer_type,values):\n",
    "    colours = cm.rainbow(np.linspace(0,1,4))\n",
    "    #f = plt.figure(figsize=(10,10))\n",
    "    #plt.axis(\"off\")\n",
    "    for i in range(4):\n",
    "        nodes_with_cancer_type = (cancer_type==i)\n",
    "        v = values[nodes_with_cancer_type]\n",
    "        x,y = v[:,0],v[:,1]\n",
    "        plt.scatter(x,y,color=colours[i])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_concept_clusters(clusters_small,t) # clusters and t must be whitened\n",
    "plot_concept_clusters(clusters_large,t) # clusters and t must be whitened\n",
    "print(len(predictions))\n",
    "plot_cancer_clusters(predictions[subset],t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Concept Completeness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activation Graph to Concept Graph\n",
    "\n",
    "\n",
    "# Attach the hook\n",
    "\n",
    "activations = []\n",
    "\n",
    "def save_activation_graph(self, input, output):\n",
    "    global activations\n",
    "    activations.append(output)\n",
    "\n",
    "\n",
    "\n",
    "model.gnn.conv[-1].register_forward_hook(save_activation_graph)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import one_hot\n",
    "\n",
    "def activation_to_concept(activation,means):\n",
    "    return one_hot(torch.as_tensor(nearest_mean(activation,means)),len(means))\n",
    "\n",
    "def activation_to_concept_graph(activations,means,k):\n",
    "    output = torch.zeros(0,k)\n",
    "    for i in range(len(activations)):\n",
    "        concept = activation_to_concept(whiten(activations[i]).numpy(),means).unsqueeze(0)\n",
    "        output = torch.cat([output,concept],dim=0)\n",
    "    return output\n",
    "\n",
    "\n",
    "def predict_activation_concept_from_graph(graph,means,k):\n",
    "    global activations\n",
    "    activations = []\n",
    "    model(graph.x,graph.edge_index,graph.batch)\n",
    "    ag = activations[0]\n",
    "    return ag,activation_to_concept_graph(ag,means,k)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch_geometric.utils import to_networkx\n",
    "import networkx as nx\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "def vizualize_concept_graph(graph,means,k):\n",
    "    print(graph.y)\n",
    "    _,x = predict_activation_concept_from_graph(graph,means,k)\n",
    "    print((x.sum(dim=0)>(len(x)/10)).sum())\n",
    "    edge_index  = graph.edge_index\n",
    "    pos = {i:tuple(graph.pos[i]) for i in range(len(graph.pos))}\n",
    "    colours = cm.rainbow(np.linspace(0,1,k))\n",
    "    node_colours = [colours[i] for i in x.argmax(dim=1)]\n",
    "    \n",
    "    g = Data(x=x,edge_index=edge_index,pos=pos)\n",
    "    G = to_networkx(graph,to_undirected=True)\n",
    "\n",
    "   # f,ax = plt.subplots(1,1,figsize=(20,20))\n",
    "    plt.figure(figsize=(graph.pos[:,0].max()/100,graph.pos[:,1].max()/100))\n",
    "    plt.axis([0,graph.pos[:,0].max(),graph.pos[:,1].max(),0])\n",
    "    nx.draw(G,pos=pos,node_color=node_colours,node_size=100)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vizualize_concept_graph(train_loader.dataset[73],means_large,k_large)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concept_vs_cancer(loader):# -> list[tuple[Tensor, Any]]: return [(predict_activation_concept_from_graph(batch,means_large,k_large)[1].mean(dim=0),batch.y) for batch in loader]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(list(map(lambda x:list(map(lambda y:y.item(),x[0])),concept_vs_cancer(train_loader))))\n",
    "y_train = np.array(list(map(lambda x:x[1].item(),concept_vs_cancer(train_loader))))\n",
    "\n",
    "x_val = np.array(list(map(lambda x:list(map(lambda y:y.item(),x[0])),concept_vs_cancer(val_loader))))\n",
    "y_val = np.array(list(map(lambda x:x[1].item(),concept_vs_cancer(val_loader))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_agg_concept_for_class(cls,x,y):\n",
    "    f = plt.figure(figsize=(20,10))\n",
    "    ind = y==cls\n",
    "    assert len(x) == len(y)\n",
    "\n",
    "    plt.imshow(x[ind].reshape(k_large,-1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_agg_concept_for_class(1,x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.as_tensor(x_train).max(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_concept_to_class_set(train_loader,means,k):\n",
    "\n",
    "    X_train = torch.zeros(0,k)\n",
    "    Y_train = torch.zeros(0)\n",
    "\n",
    "    for graph in train_loader:\n",
    "        num_nodes = len(graph.x)\n",
    "        y = torch.zeros(num_nodes) + graph.y\n",
    "        _,x = predict_activation_concept_from_graph(graph,means,k)\n",
    "        X_train = torch.cat([X_train,x],dim=0)\n",
    "        Y_train = torch.cat([Y_train,y],dim=0)\n",
    "    return X_train,Y_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,Y_train = generate_concept_to_class_set(train_loader,means_large,k_large)\n",
    "X_val,Y_val = generate_concept_to_class_set(val_loader,means_large,k_large)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### CBE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Linear Model\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import sklearn.tree as tree\n",
    "\n",
    "\n",
    "l = tree.DecisionTreeClassifier(criterion=\"entropy\").fit(X_train,Y_train)\n",
    "\n",
    "tree.plot_tree(l)\n",
    "\n",
    "print(l.score(X_train,Y_train))\n",
    "print(l.score(X_val,Y_val))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See P(class|concept)\n",
    "from tqdm import tqdm\n",
    "from torch.nn.functional import normalize\n",
    "\n",
    "\n",
    "def class_concept_joint_frequency(CLS,CONCEPT,k):\n",
    "    class_concept = torch.zeros(4,k)\n",
    "    for cons,cl in tqdm(zip(CONCEPT,CLS)):\n",
    "        class_concept[cl.int(),cons.argmax()] += 1\n",
    "    return class_concept\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def class_condition_concepts_prob(joint_freq,concepts): # concepts in number form\n",
    "    output = torch.zeros(4)\n",
    "    joint_freq+=1\n",
    "    def _p_class(cl): return joint_freq[cl].sum()/joint_freq.sum()\n",
    "    def _p_concept(cons): return joint_freq[:,cons].sum()/joint_freq.sum()\n",
    "    def _p_concept_given_class(cons,cl): return joint_freq[cl,cons]/joint_freq[cl].sum()\n",
    "    for cl in range(4):\n",
    "        tot = torch.log(_p_class(cl))\n",
    "        for cons in concepts:\n",
    "            tot  += torch.log(_p_concept_given_class(cons,cl))\n",
    "            tot -= torch.log(_p_concept(cons))\n",
    "        output[cl] = tot\n",
    "    return output       \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = class_concept_joint_frequency(Y_train,X_train)\n",
    "class_condition_concepts_prob(freq,X_train[0:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import normalize\n",
    "\n",
    "z = normalize(freq,dim=1,p=1)\n",
    "y = torch.zeros(k,2)\n",
    "y[:,0] = z[:,0]+z[:,1]\n",
    "y[:,1] = z[:,2]+z[:,3]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Deducing K\n",
    "\n",
    "\n",
    "1) Choose K\n",
    "2) Get Convert list of graphs to list of (activation, graph id)\n",
    "3) Get list (graph_id, ground_truth, pred_truth)\n",
    "4) Generate means and hence concepts from activations\n",
    "5) Get concepts from activations\n",
    "6) Use decision tree to predict (concept-> cancer_type)\n",
    "7) Evaluate how accurate\n",
    "8) **Define concept prevelance score** and evaluate. If below certain threshold\n",
    "9) Increment K and plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_concept_means(model,train_loader,k):\n",
    "    global raw_activations\n",
    "    raw_activations = torch.zeros(0,32)\n",
    "\n",
    "    for batch in tqdm(train_loader):\n",
    "        model(batch.x,batch.edge_index,batch.batch)\n",
    "\n",
    "    #for batch in val_loader:\n",
    "    #    model(batch.x,batch.edge_index,batch.batch)\n",
    "\n",
    "    obs = raw_activations.detach().numpy()\n",
    "    mu,sigma = obs.mean(axis=0),obs.std(axis=0)\n",
    "\n",
    "    def whiten(obs):\n",
    "        return (obs - mu)/sigma\n",
    "\n",
    "    obs_white = whiten(obs)\n",
    "    means = MiniBatchKMeans(n_clusters=k,batch_size=10000).fit(obs_white).cluster_centers_\n",
    "    return means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import sklearn.tree as tree\n",
    "\n",
    "def first(x): return x[0]\n",
    "def second(x): return x[1]\n",
    "def third(x): return x[2]\n",
    "\n",
    "\n",
    "\n",
    "def deduce_k(train_loader,val_loader,model,max_k=60,increments=6,start_k=10):\n",
    "    global activations\n",
    "    ks = []\n",
    "    dt_scores_val = []\n",
    "    dt_scores_train = []\n",
    "    predictive_power_node = []\n",
    "    predictive_power_subgraph = []\n",
    "    prevelance = []\n",
    "    for k in tqdm(range(start_k,max_k,increments)):\n",
    "        #Generate\n",
    "        means = generate_concept_means(model,train_loader,k)\n",
    "        \n",
    "    \n",
    "        \n",
    "        X_train,Y_train = generate_concept_to_class_set(train_loader,means,k)\n",
    "        X_val,Y_val = generate_concept_to_class_set(val_loader,means,k)\n",
    "        freq = class_concept_joint_frequency(Y_train,X_train,k) +1\n",
    "        \n",
    "        \n",
    "        #Train\n",
    "\n",
    "        \n",
    "        dt = tree.DecisionTreeClassifier(criterion=\"entropy\").fit(X_train,Y_train)\n",
    "        \n",
    "        \n",
    "        \n",
    "        #Test\n",
    "        node_correct = 0\n",
    "        subgraph_correct = 0\n",
    "\n",
    "        concept_prev = torch.zeros(k)\n",
    "        for graph in val_loader:\n",
    "            \n",
    "            concept_graph = activation_graph_to_concept_graph(graph,means,k)\n",
    "            concepts = concept_graph.x.argmax(dim=1)\n",
    "            sub_graphs_concepts = set(map(lambda g: g.concept.item(),disect_concept_graph(concept_graph)))\n",
    "            #print(class_condition_concepts_prob(freq,concepts).argmax(),graph.y)\n",
    "            node_correct += 1 if class_condition_concepts_prob(freq,concepts).argmax() == graph.y else 0\n",
    "            subgraph_correct += 1 if class_condition_concepts_prob(freq,list(sub_graphs_concepts)).argmax() == graph.y else 0\n",
    "            for concept in sub_graphs_concepts: \n",
    "                concept_prev[concept] +=1\n",
    "        prevelance.append(concept_prev/len(val_loader))\n",
    "        \n",
    "        ks.append(k)\n",
    "        dt_scores_val.append(dt.score(X_val,Y_val))\n",
    "        dt_scores_train.append(dt.score(X_train,Y_train))\n",
    "        predictive_power_node.append(node_correct/len(val_loader))\n",
    "        predictive_power_subgraph.append(subgraph_correct/len(train_loader))\n",
    "\n",
    "    return ks,dt_scores_train,dt_scores_val,predictive_power_node,predictive_power_subgraph,prevelance\n",
    "        \n",
    "ks,dt_train,dt_val,pp_node,pp_subgraph,prevelance= deduce_k(train_loader,val_loader,model,max_k=34,increments=2,start_k=30)\n",
    "#print(prevelance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(ks,dt_train)\n",
    "plt.plot(ks,dt_val)\n",
    "plt.plot(ks,pp_node)\n",
    "plt.show()\n",
    "min_prevelance = list(map(lambda x: x*100,map(min,prevelance)))\n",
    "plt.plot(ks,min_prevelance,lw=2,c=\"b\")\n",
    "for i,min_prev in enumerate(min_prevelance[::2]):\n",
    "    label = str(min_prev.int().item())\n",
    "    i=i*2\n",
    "    plt.annotate(label, # this is the text\n",
    "                 (ks[i],min_prevelance[i]), # these are the coordinates to position the label\n",
    "                 textcoords=\"offset points\", # how to position the text\n",
    "                 xytext=(-5,-10), # distance from text to points (x,y)\n",
    "                 ha='center') # horizontal alignment can be left, right or center\n",
    "    \n",
    "plt.xlabel(\"Number of concepts k\")\n",
    "plt.ylabel(\"Minimum prevelance as %\")\n",
    "plt.title(\"Minimum prevelance of concepts in validation set against k\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Concept Discovery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Concept Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DISCOVER CONCEPTS\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.cluster import KMeans,MiniBatchKMeans\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "k=32\n",
    "\n",
    "\n",
    "means = generate_concept_means(model,train_loader,k)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import one_hot\n",
    "\n",
    "def activation_to_concept(activation,means):\n",
    "    return one_hot(torch.as_tensor(nearest_mean(activation,means)),len(means))\n",
    "\n",
    "def activation_to_concept_graph(activations,means,k):\n",
    "    output = torch.zeros(0,k)\n",
    "    for i in range(len(activations)):\n",
    "        concept = activation_to_concept(whiten(activations[i]).numpy(),means).unsqueeze(0)\n",
    "        output = torch.cat([output,concept],dim=0)\n",
    "    return output\n",
    "\n",
    "\n",
    "def predict_activation_concept_from_graph(graph,means,k):\n",
    "    global activations\n",
    "    activations = []\n",
    "    model(graph.x,graph.edge_index,graph.batch)\n",
    "    ag = activations[0]\n",
    "    return ag,activation_to_concept_graph(ag,means,k)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For determining how what sort of cancer diagnosis a concept indicates\n",
    "\n",
    "X_train = torch.zeros(0,k)\n",
    "Y_train = torch.zeros(0)\n",
    "\n",
    "for graph in tqdm(train_loader):\n",
    "    num_nodes = len(graph.x)\n",
    "\n",
    "    y = torch.zeros(num_nodes) + graph.y\n",
    "    _,x = predict_activation_concept_from_graph(graph,means,k)\n",
    "    X_train = torch.cat([X_train,x],dim=0)\n",
    "    Y_train = torch.cat([Y_train,y],dim=0)\n",
    "\n",
    "\n",
    "\n",
    "#class_condition_concepts_prob(freq,X_train[0:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(Y_train[X_train.argmax(dim=1)==2]))\n",
    "freq = class_concept_joint_frequency(Y_train,X_train,k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_class_given_concept = (freq.transpose(1,0)).int() # /freq.reshape(-1,4).sum(dim=1,keepdim=True))*100\n",
    "print(freq.shape)\n",
    "p_class_given_concept = ((freq/freq.transpose(1,0).sum(dim=1)).transpose(1,0)*100).int()\n",
    "print(p_class_given_concept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from torch_geometric.utils import to_networkx, from_networkx\n",
    "\n",
    "#todo rename\n",
    "def activation_graph_to_concept_graph(graph,means,k):\n",
    "    output = graph.clone()\n",
    "    output.activation,output.x = predict_activation_concept_from_graph(graph,means,k)\n",
    "    return output\n",
    "\n",
    "\n",
    "def disect_concept_graph(concept_graph,min_subgraph_size=5):\n",
    "    graph = concept_graph.clone()\n",
    "\n",
    "    left_nodes,right_nodes = concept_graph.x[graph.edge_index[0,:]].argmax(dim=1),concept_graph.x[graph.edge_index[1,:]].argmax(dim=1)\n",
    "\n",
    "    keep_edge = left_nodes==right_nodes\n",
    "    graph.edge_index = graph.edge_index[:,keep_edge]\n",
    "    \n",
    "    G = to_networkx(graph, to_undirected=True, node_attrs=['x','activation','pos'])\n",
    "    \n",
    "    sub_graphs = [G.subgraph(g) for g in nx.components.connected_components(G) if len(g) >= min_subgraph_size]\n",
    "    for i,g in enumerate(sub_graphs):\n",
    "        g = from_networkx(g,group_node_attrs=['activation','x','pos'])\n",
    "        g.pos = g.x[:,-2:]\n",
    "        g.activation = g.x[:,:32]\n",
    "        g.x = g.x[:,32:-2]\n",
    "        g.graph_id = graph.graph_id\n",
    "        g.y = graph.y.item()\n",
    "\n",
    "        g.concept = g.x[0].argmax()\n",
    "        sub_graphs[i] = g\n",
    "    return sub_graphs\n",
    "\n",
    "\n",
    "        \n",
    "graph = next(iter(train_loader))\n",
    "\n",
    "\n",
    "cg = activation_graph_to_concept_graph(graph[0],means,k)\n",
    "print(disect_concept_graph(cg,min_subgraph_size=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET ALL CANDIDATE EXEMPLARY GRAPHS\n",
    "exemplary_concept_graphs = [[] for i in range(k)]\n",
    "\n",
    "for i,graph in tqdm(enumerate(train_loader),total=len(train_loader)):\n",
    "    sub_graphs = disect_concept_graph(activation_graph_to_concept_graph(graph[0],means,k),min_subgraph_size=5)\n",
    "    for sg in sub_graphs:\n",
    "        exemplary_concept_graphs[sg.concept].append(sg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(map(len,exemplary_concept_graphs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILTER FOR 3 most Interesting\n",
    "\n",
    "def sieve_graph_id(li):\n",
    "    output = []\n",
    "    for i,(score,g) in enumerate(li):\n",
    "        unique = True\n",
    "        for j,g2 in enumerate(output):\n",
    "            if g.graph_id == g2.graph_id:\n",
    "                unique = False\n",
    "                break\n",
    "        if unique:\n",
    "            output.append(g)\n",
    "    return output\n",
    "\n",
    "\n",
    "\n",
    "exemplary_concept_graphs_final = list(exemplary_concept_graphs)\n",
    "print(len(exemplary_concept_graphs_final))\n",
    "\n",
    "def score_subgraph(sg,mean):\n",
    "    dists = ((sg.activation - mean)**2).sum(dim=1)\n",
    "    assert len(dists)==len(sg.activation)\n",
    "    return dists.median()\n",
    "\n",
    "for cons in tqdm(range(k)):\n",
    "    \n",
    "    #only_supporting_graphs = list(filter(lambda g: g.y== p_class_given_concept[cons].argmax(),exemplary_concept_graphs[cons]))\n",
    "    #if len(only_supporting_graphs)==0:\n",
    "    #    print(cons,p_class_given_concept[cons].argmax(),list(map(lambda x: x.y, exemplary_concept_graphs[cons])))\n",
    "    best_examples = sieve_graph_id(sorted(map(lambda x:(score_subgraph(x,means[cons]),x),exemplary_concept_graphs[cons]),key=lambda x:x[0]))\n",
    "    \n",
    "    best_examples = best_examples[:min(3,len(best_examples))] \n",
    "    exemplary_concept_graphs_final[cons] = best_examples\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(map(len,exemplary_concept_graphs_final)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cons in range(k):\n",
    "    print(cons,list(map(lambda x: x.y, exemplary_concept_graphs_final[cons])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bach_source=  os.path.join(parent, 'data', 'processed', 'BACH_TRAIN')\n",
    "def bach_img_loc(img_id):\n",
    "    b = BACH(bach_source)\n",
    "    b.ids= list(range(1,401))\n",
    "    img_path = b.original_image_paths[img_id-1]\n",
    "    return img_path\n",
    "\n",
    "def visualise_bach_subgraph(sg,crop=True,save=False,save_loc=None):\n",
    "\n",
    "    img_path = bach_img_loc(sg.graph_id)\n",
    "    visualise_concept_subgraph(sg,img_path,means,crop=crop,save=save,save_loc=save_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.datasets.BACH import BACH, _id_to_path\n",
    "from PIL import Image\n",
    "from scipy.spatial import ConvexHull\n",
    "from src.transforms.graph_construction.hovernet_post_processing import cut_img_from_tile\n",
    "from torchvision.transforms import ToTensor\n",
    "from src.utilities.img_utilities import tensor_to_numpy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "\n",
    "\n",
    "def create_point_sphere(centre:torch.Tensor,radius,n_points):\n",
    "    output = []\n",
    "    for theta in np.linspace(0,2*np.pi,n_points):\n",
    "\n",
    "        output += [centre + radius*torch.as_tensor([torch.cos(torch.as_tensor(theta)),torch.sin(torch.as_tensor(theta))])]\n",
    "    return torch.stack(output)\n",
    "\n",
    "def visualise_concept_subgraph(sg,image_loc,concept_means,crop=True,save=False,save_loc=None):\n",
    "    # Load the image\n",
    "    img = tensor_to_numpy(cut_img_from_tile(ToTensor()(Image.open(image_loc)),tile_size=128))\n",
    "    # Place nodes on the image\n",
    "    # Place smoothing sphere around cells\n",
    "    # Convex hull around\n",
    "    points = torch.zeros(0,2)\n",
    "    centres = []\n",
    "    distances = ((sg.activation - concept_means[sg.concept])**2).sum(dim=1)\n",
    "    height = []\n",
    "    for i in range(len(sg.x)):\n",
    "        centre = sg.pos[i]\n",
    "        centres.append(centre)\n",
    "        height.append(distances[i])\n",
    "        cell_points = create_point_sphere(centre,64,10)\n",
    "        points = torch.cat([points,cell_points])\n",
    "    points = points[ConvexHull(points.numpy()).vertices]\n",
    "    points = torch.cat([points,points[0].unsqueeze(0)])\n",
    "    centres = torch.stack(centres)\n",
    "    height = torch.stack(height)\n",
    "    height = (height-height.min())/(height.max()-height.min())\n",
    "    colours = cm.cool(height)\n",
    "    \n",
    "    f = plt.figure(figsize=(10,10))\n",
    "    plt.axis('off')\n",
    "    plt.plot(points[:,0].numpy(),points[:,1].numpy(),'b-',lw=5)\n",
    "    plt.scatter(centres[:,0].numpy(),centres[:,1].numpy(),c =colours,s=50)\n",
    "    if(crop):\n",
    "        padding = 10\n",
    "        xmin = int(max((points[:,0].numpy()-padding).min(),0))\n",
    "        xmax = int(min((points[:,0].numpy()+padding).max(),img.shape[1]))\n",
    "        ymin = int(max((points[:,1].numpy()-padding).min(),0))\n",
    "        y_max = int(min((points[:,1].numpy()+padding).max(),img.shape[0]))\n",
    "        plt.xlim(xmin,xmax)\n",
    "        plt.ylim(ymin,y_max)\n",
    "\n",
    "    plt.imshow(img)\n",
    "    \n",
    "    if(save and save_loc is not None):\n",
    "        plt.savefig(save_loc)\n",
    "        plt.close(f)\n",
    "\n",
    "\n",
    "\n",
    "    # Convert convex hull shape to shape object PIL\n",
    "    # Fill shape and use as mask to place over image.\n",
    "    # Colour border by concept number\n",
    "    \n",
    "i = 23\n",
    "for j in range(3):\n",
    "    visualise_bach_subgraph(exemplary_concept_graphs_final[i][j],crop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utilities.os_utilities import create_dir_if_not_exist\n",
    "def save_discovered_concepts(folder_location,concept_means,exemplary_concept_graphs_final,class_concept_prob):\n",
    "    create_dir_if_not_exist(folder_location,file_path=False)\n",
    "    np.save(os.path.join(folder_location,'concept_means.npy'),concept_means)\n",
    "    np.save(os.path.join(folder_location,'class_concept_prob.npy'),class_concept_prob)\n",
    "    for cons in range(len(concept_means)):\n",
    "        for i,cons_example in enumerate(exemplary_concept_graphs_final[cons]):\n",
    "            visualise_bach_subgraph(cons_example,crop=True,save=True,save_loc=os.path.join(folder_location,'c'+str(cons)+'e'+str(i)+'.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_discovered_concepts(os.path.join(parent, 'data', 'processed', 'CONCEPTS'),means,exemplary_concept_graphs_final,p_class_given_concept)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Good ones\n",
    "60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "# Explaining Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO EXTEND TO LIST OF SUBGRAPHS\n",
    "def visualise_concept_subgraphs(sgs,image_loc,concept_means,save=False,save_loc=None,ax=None,crop=False):\n",
    "    if ax is None:\n",
    "        f = plt.figure(figsize=(10,10))\n",
    "        ax = f.add_subplot(111)\n",
    "    plt.axis('off')\n",
    "    # Load the image\n",
    "    img = tensor_to_numpy(cut_img_from_tile(ToTensor()(Image.open(image_loc)),tile_size=128))\n",
    "    # Place nodes on the image\n",
    "    # Place smoothing sphere around cells\n",
    "    # Convex hull around\n",
    "    for sg in sgs:\n",
    "        points = torch.zeros(0,2)\n",
    "        centres = []\n",
    "        distances = ((sg.activation - concept_means[sg.concept])**2).sum(dim=1)\n",
    "        height = []\n",
    "        for i in range(len(sg.x)):\n",
    "            centre = sg.pos[i]\n",
    "            centres.append(centre)\n",
    "            height.append(distances[i])\n",
    "            cell_points = create_point_sphere(centre,64,10)\n",
    "            points = torch.cat([points,cell_points])\n",
    "        points = points[ConvexHull(points.numpy()).vertices]\n",
    "        points = torch.cat([points,points[0].unsqueeze(0)]) \n",
    "        ax.plot(points[:,0].numpy(),points[:,1].numpy(),'b-',lw=5)\n",
    "        \n",
    "    if(crop):\n",
    "        padding = 10\n",
    "        xmin = int(max((points[:,0].numpy()-padding).min(),0))\n",
    "        xmax = int(min((points[:,0].numpy()+padding).max(),img.shape[1]))\n",
    "        ymin = int(max((points[:,1].numpy()-padding).min(),0))\n",
    "        y_max = int(min((points[:,1].numpy()+padding).max(),img.shape[0]))\n",
    "        ax.set_xlim(xmin,xmax)\n",
    "        ax.set_ylim(ymin,y_max)\n",
    "\n",
    "    ax.imshow(img,aspect='auto')\n",
    "    \n",
    "    if(save and save_loc is not None):\n",
    "        plt.savefig(save_loc)\n",
    "        plt.close(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 73\n",
    "graph = train_loader.dataset[i]\n",
    "print(graph.graph_id)\n",
    "print(bach_img_loc(graph.graph_id))\n",
    "concept_graph = activation_graph_to_concept_graph(graph,means,k)\n",
    "sgs = disect_concept_graph(concept_graph,min_subgraph_size=20)\n",
    "print(list(map(lambda x:x.concept,sgs)))\n",
    "visualise_concept_subgraphs(sgs,bach_img_loc(graph.graph_id),means)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #p_canc_given_concept = torch.zeros(k,2)\n",
    "    #p_canc_given_concept[:,0] = p_class_given_concept[:,0] + p_class_given_concept[:,1]\n",
    "    #p_canc_given_concept[:,1] = p_class_given_concept[:,2] + p_class_given_concept[:,3]\n",
    "    #p_canc_given_concept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "\n",
    "\n",
    "def explain_prediction(graph,prediction,means,k,p_class_given_concept,exemplary_concept_graphs_final):\n",
    "    # ORDER BY COUNT\n",
    "    sgs = disect_concept_graph(activation_graph_to_concept_graph(graph,means,k),min_subgraph_size=15)\n",
    "    assert p_class_given_concept.shape == (k,4)\n",
    "    #p_canc_given_concept = torch.zeros(k,2)\n",
    "    #p_canc_given_concept[:,0] = p_class_given_concept[:,0] + p_class_given_concept[:,1]+1\n",
    "    #p_canc_given_concept[:,1] = p_class_given_concept[:,2] + p_class_given_concept[:,3]+1 #laplace smoothing\n",
    "    #\n",
    "    #is_canc = prediction>=2\n",
    "    #canc_evidence = sorted(list(filter(lambda g:p_canc_given_concept[g.concept][1]>50,sgs)),key=lambda g:p_canc_given_concept[g.concept][1],reverse=True)\n",
    "    #non_canc_evidence = sorted(list(filter(lambda g:p_canc_given_concept[g.concept][0]>50,sgs)),key=lambda g:p_canc_given_concept[g.concept][0],reverse=True)\n",
    "    #if is_canc:\n",
    "    #    support,contrary = canc_evidence,non_canc_evidence\n",
    "    #else:\n",
    "    #    support,contrary = non_canc_evidence,canc_evidence\n",
    "    #    \n",
    "    #return support,contrary\n",
    "    \n",
    "    evidence = sorted(list(filter(lambda g:p_class_given_concept[g.concept][prediction]>50,sgs)),key=lambda g:p_class_given_concept[g.concept][prediction],reverse=True)\n",
    "    primary_concept = evidence[0].concept\n",
    "    primary_evidence = list(filter(lambda g:g.concept==primary_concept,evidence))\n",
    "    print(primary_evidence)\n",
    "    \n",
    "    f = plt.figure(figsize=(20,10))\n",
    "    gs = GridSpec(nrows=3, ncols=7)\n",
    "    ax_main = f.add_subplot(gs[:,:5])\n",
    "    ax_main.title.set_text('Prediction:\\n'+['Normal','Benign','In-Situ','Invasive'][prediction])\n",
    "    ax_main.title.set_fontsize(40)\n",
    "    visualise_concept_subgraphs(primary_evidence,bach_img_loc(graph.graph_id),means,ax=ax_main)\n",
    "    ax_concepts = [f.add_subplot(gs[i:i+1,6:]) for i in range(3)]\n",
    "    ax_concepts[0].title.set_text('Supporting Concept:\\n#'+str(primary_concept.item()))\n",
    "    ax_concepts[0].title.set_fontsize(40)\n",
    "    for i,sg in enumerate(exemplary_concept_graphs_final[primary_concept]):\n",
    "        ax_concepts[i].axis('off')\n",
    "        visualise_concept_subgraphs([sg],bach_img_loc(sg.graph_id),means,ax=ax_concepts[i],crop=True)\n",
    "    \n",
    "    \n",
    "graph_pred = model(graph.x,graph.edge_index,graph.batch)\n",
    "\n",
    "evidence = explain_prediction(graph,graph_pred.argmax(),means,k,p_class_given_concept,exemplary_concept_graphs_final)\n",
    "\n",
    "#visualise_concept_subgraphs(evidence,bach_img_loc(graph.graph_id),means)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e591b006129f0dfb1d51895b4ed619a4625402ac1a377124080c35d47fc6e9a2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
