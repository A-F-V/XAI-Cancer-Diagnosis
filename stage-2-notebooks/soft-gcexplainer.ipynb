{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Soft-GCExplainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\Documents\\git\\XAI-Cancer-Diagnosis\\XAI-Cancer-Diagnosis\n"
     ]
    }
   ],
   "source": [
    "import os,sys\n",
    "\n",
    "parent = os.path.dirname(os.getcwd())\n",
    "if parent not in sys.path:\n",
    "    sys.path.append(parent)\n",
    "print(parent)\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_settings = {'evaluate_model':False, 'save_concepts': False, 'tsne':False}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model & Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available:  True\n",
      "CUDA device count:  1\n",
      "77\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "# Data\n",
    "\n",
    "from src.datasets.BACH import BACH\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.transforms import Compose, KNNGraph\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "graph_aug_val = Compose([KNNGraph(k=6)])\n",
    "\n",
    "\n",
    "print('CUDA available: ', torch.cuda.is_available())\n",
    "print('CUDA device count: ', torch.cuda.device_count())\n",
    "\n",
    "src_folder = os.path.join(\n",
    "    \"C://Users\", \"aless\", \"Documents\", \"FtT\", \"data\", \"BACH_TRAIN\")\n",
    "tid,vid = BACH.get_train_val_ids(src_folder,\"graph_ind_FtT_19_11_1.txt\")\n",
    "train_set = BACH(src_folder,graph_augmentation=graph_aug_val,ids=tid,pre_encoded=True)\n",
    "val_set = BACH(src_folder,graph_augmentation=graph_aug_val,ids=vid,pre_encoded=True)\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=4, shuffle=False)\n",
    "val_loader = DataLoader(val_set, batch_size=4, shuffle=False)\n",
    "\n",
    "print(len(train_loader))\n",
    "print(len(val_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CancerGNN(\n",
      "  (gnn): GCNx(\n",
      "    (conv): ModuleList(\n",
      "      (0): GCNConv(64, 64)\n",
      "      (1): GCNConv(64, 64)\n",
      "      (2): GCNConv(64, 64)\n",
      "      (3): GCNConv(64, 64)\n",
      "      (4): GCNConv(64, 64)\n",
      "      (5): GCNConv(64, 64)\n",
      "      (6): GCNConv(64, 64)\n",
      "    )\n",
      "    (transform): ModuleList(\n",
      "      (0): Sequential(\n",
      "        (0): BatchNorm1d(312, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (1): ReLU()\n",
      "        (2): Dropout(p=0.1, inplace=False)\n",
      "        (3): Linear(in_features=312, out_features=64, bias=True)\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): BatchNorm1d(64, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (1): ReLU()\n",
      "        (2): Dropout(p=0, inplace=False)\n",
      "        (3): Linear(in_features=64, out_features=64, bias=True)\n",
      "      )\n",
      "      (2): Sequential(\n",
      "        (0): BatchNorm1d(64, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (1): ReLU()\n",
      "        (2): Dropout(p=0, inplace=False)\n",
      "        (3): Linear(in_features=64, out_features=64, bias=True)\n",
      "      )\n",
      "      (3): Sequential(\n",
      "        (0): BatchNorm1d(64, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (1): ReLU()\n",
      "        (2): Dropout(p=0, inplace=False)\n",
      "        (3): Linear(in_features=64, out_features=64, bias=True)\n",
      "      )\n",
      "      (4): Sequential(\n",
      "        (0): BatchNorm1d(64, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (1): ReLU()\n",
      "        (2): Dropout(p=0, inplace=False)\n",
      "        (3): Linear(in_features=64, out_features=64, bias=True)\n",
      "      )\n",
      "      (5): Sequential(\n",
      "        (0): BatchNorm1d(64, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (1): ReLU()\n",
      "        (2): Dropout(p=0, inplace=False)\n",
      "        (3): Linear(in_features=64, out_features=64, bias=True)\n",
      "      )\n",
      "      (6): Sequential(\n",
      "        (0): BatchNorm1d(64, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        (1): ReLU()\n",
      "        (2): Dropout(p=0, inplace=False)\n",
      "        (3): Linear(in_features=64, out_features=64, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (predictor): Sequential(\n",
      "    (0): Dropout(p=0.2, inplace=False)\n",
      "    (1): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (2): BatchNorm1d(64, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
      "    (3): ReLU()\n",
      "    (4): Dropout(p=0, inplace=False)\n",
      "    (5): Linear(in_features=64, out_features=4, bias=True)\n",
      "  )\n",
      ")\n",
      "Sequential(\n",
      "  (0): Dropout(p=0.2, inplace=False)\n",
      "  (1): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (2): BatchNorm1d(64, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
      "  (3): ReLU()\n",
      "  (4): Dropout(p=0, inplace=False)\n",
      "  (5): Linear(in_features=64, out_features=4, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "\n",
    "from src.deep_learning.architectures.cancer_prediction.cancer_gnn import CancerGNN\n",
    "\n",
    "model = CancerGNN.load_from_checkpoint(os.path.join(parent,\"experiments\",\"checkpoints\", \"FtT_FtT_19_11_1.ckpt\"),WIDTH=64,HEIGHT=7)\n",
    "\n",
    "print(model)\n",
    "print(model.predictor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Raw Activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Width:  64\n"
     ]
    }
   ],
   "source": [
    "model_width = model.width\n",
    "print(\"Model Width: \",model_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77/77 [00:16<00:00,  4.66it/s]\n",
      "100%|██████████| 20/20 [00:04<00:00,  4.71it/s]\n",
      "100%|██████████| 77/77 [00:15<00:00,  4.94it/s]\n",
      "100%|██████████| 20/20 [00:04<00:00,  4.46it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from torch import softmax\n",
    "\n",
    "class RawActivationHook:\n",
    "    def __init__(self,width,device='cuda'):\n",
    "        self.activations = torch.zeros(0,width).to(device)\n",
    "    \n",
    "    def append_activations(self, model,input, output):\n",
    "        self.activations = torch.cat((self.activations,output),dim=0)\n",
    "        \n",
    "    def __enter__(self):\n",
    "        self.remove_handle = model.gnn.conv[-1].register_forward_hook(lambda m,i,o:(self.append_activations(m,i,o)))\n",
    "        return self\n",
    "    \n",
    "    def __exit__(self, type, value, traceback):\n",
    "        self.remove_handle.remove()\n",
    "        \n",
    "    def get_activations(self):\n",
    "        return self.activations\n",
    "\n",
    "class ModelForward:\n",
    "    def __init__(self,model):\n",
    "        self.model = model\n",
    "        self.model_width  = model.width\n",
    "        self.model.eval()\n",
    "        self.model.to('cuda')\n",
    "        \n",
    "    def forward_node_level(self,loader):\n",
    "        # Acquire the activations\n",
    "        hook = RawActivationHook(self.model_width)\n",
    "\n",
    "\n",
    "        \n",
    "        predictions = torch.zeros(0).to('cuda')\n",
    "        ground = torch.zeros(0).to('cuda')\n",
    "        \n",
    "        with hook:\n",
    "            for batch in tqdm(loader):\n",
    "                batch = batch.to('cuda')\n",
    "                output = model.forward(batch.x,batch.edge_index,batch.batch)\n",
    "                \n",
    "                node_probs = softmax(output,dim=1)[batch.batch]\n",
    "                node_ground = batch.y[batch.batch]\n",
    "                \n",
    "                \n",
    "                predictions = torch.cat([predictions,node_probs])\n",
    "                ground = torch.cat([ground,node_ground])\n",
    "            \n",
    "        raw_activations = hook.get_activations()\n",
    "        return raw_activations.cpu().detach().numpy(),predictions.cpu().detach().numpy(),ground.cpu().detach().numpy().astype(int)\n",
    "    \n",
    "    def forward_graph_level(self,loader):\n",
    "        predictions = torch.zeros(0).to('cuda')\n",
    "        ground = torch.zeros(0).to('cuda')\n",
    "        \n",
    "        for batch in tqdm(loader):\n",
    "            batch = batch.to('cuda')\n",
    "            output = model.forward(batch.x,batch.edge_index,batch.batch)\n",
    "            \n",
    "            graph_probs = softmax(output,dim=1)\n",
    "            graph_ground = batch.y\n",
    "            \n",
    "            predictions = torch.cat([predictions,graph_probs])\n",
    "            ground = torch.cat([ground,graph_ground])\n",
    "            \n",
    "        return predictions.cpu().detach().numpy(),ground.cpu().detach().numpy().astype(int)\n",
    "\n",
    "forwarder = ModelForward(model)\n",
    "\n",
    "graph_prob_predictions_train,graph_ground_train = forwarder.forward_graph_level(train_loader)\n",
    "graph_prob_predictions_val,graph_ground_val = forwarder.forward_graph_level(val_loader)\n",
    "\n",
    "activations_train,node_predictions_train,node_ground_train  = forwarder.forward_node_level(train_loader)\n",
    "activations_val,node_predictions_val,node_ground_val = forwarder.forward_node_level(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_predictions_train = np.argmax(graph_prob_predictions_train,axis=1)\n",
    "graph_predictions_val = np.argmax(graph_prob_predictions_val,axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy on validation set: 0.7662337662337663\n",
      "Model accuracy on training set: 0.935064935064935\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model accuracy on validation set: {np.sum(graph_predictions_val == graph_ground_val)/len(graph_ground_val)}\")\n",
    "print(f\"Model accuracy on training set: {np.sum(graph_predictions_train == graph_ground_train)/len(graph_ground_train)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# K Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "class ConceptDiscoverer:\n",
    "    def __init__(self,num_concepts,verbose=True) -> None:\n",
    "        self.k = num_concepts\n",
    "        self.gm = GaussianMixture(n_components=self.k,verbose=verbose)\n",
    "        \n",
    "    def fit(self,activations: np.ndarray):\n",
    "        self.mu = activations.mean(axis=0)\n",
    "        self.sigma = activations.std(axis=0)\n",
    "        \n",
    "        whitten_activations = ConceptDiscoverer.whiten(activations,self.mu,self.sigma)\n",
    "        \n",
    "        self.gm.fit(whitten_activations)\n",
    "    \n",
    "    def predict(self,activations):\n",
    "        whitten_activations = ConceptDiscoverer.whiten(activations,self.mu,self.sigma)\n",
    "        return self.gm.predict(whitten_activations)\n",
    "        \n",
    "    def predict_proba(self,activations):\n",
    "        whitten_activations = ConceptDiscoverer.whiten(activations,self.mu,self.sigma)\n",
    "        return self.gm.predict_proba(whitten_activations)\n",
    "        \n",
    "        \n",
    "    @staticmethod\n",
    "    def whiten(obs,mu,sigma):\n",
    "        return (obs - mu)/sigma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization 0\n",
      "  Iteration 10\n",
      "  Iteration 20\n",
      "  Iteration 30\n",
      "Initialization converged: True\n"
     ]
    }
   ],
   "source": [
    "sub_sample_size = 10000\n",
    "sub_sample = np.random.choice(activations_train.shape[0],sub_sample_size,replace=False)\n",
    "\n",
    "num_concepts =64\n",
    "\n",
    "cd = ConceptDiscoverer(num_concepts=num_concepts)\n",
    "cd.fit(activations_train[sub_sample,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_concept_probs = cd.predict_proba(activations_train)\n",
    "val_concept_probs = cd.predict_proba(activations_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rejection Sampling\n",
    "What if we consider only those activations that are we have a certain degree of confidence is in that concept?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  0.9669711264771256\n",
      "Val:  0.9590673302261895\n"
     ]
    }
   ],
   "source": [
    "def within_acceptance(probabilities:np.ndarray,threshold = 0.9):\n",
    "    max_prob = probabilities.max(axis=1)\n",
    "    assert(max_prob.shape[0] == probabilities.shape[0])\n",
    "    number_surpass = (max_prob > threshold).sum()\n",
    "    return number_surpass / probabilities.shape[0]\n",
    "\n",
    "print(\"Train: \",within_acceptance(train_concept_probs))\n",
    "print(\"Val: \",within_acceptance(val_concept_probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "if notebook_settings['save_concepts']:\n",
    "    np.save(\"mu.npy\",mu)\n",
    "    np.save(\"sigma.npy\",sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Vizualize Explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'tsne'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16660/2066455609.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mif\u001b[0m \u001b[0mnotebook_settings\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'tsne'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mtsne_sample_size\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[1;36m50000\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mtsne_sample\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_obs_white\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtsne_sample_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'tsne'"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "\n",
    "if notebook_settings['tsne']:\n",
    "    tsne_sample_size  = 50000\n",
    "    tsne_sample= np.random.choice(train_obs_white.shape[0],tsne_sample_size,replace=False)\n",
    "    position_tsne_sample =TSNE(n_components=2,verbose=2,perplexity = 1000,n_iter=400).fit_transform(train_obs_white[tsne_sample])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "\n",
    "def plot_tsne_points_with_category(points,classes):\n",
    "    f = plt.figure(figsize=(10,10))\n",
    "    # How many different classes are there\n",
    "    unique_classes = np.unique(classes)\n",
    "    colours = cm.rainbow(np.linspace(0,1,len(unique_classes)))\n",
    "    \n",
    "    # Group the points by their class and then plot all points of the same class at a time\n",
    "    for i,cl in enumerate(unique_classes):\n",
    "        points_with_class = (classes==cl)\n",
    "        v = points[points_with_class]\n",
    "        x,y = v[:,0],v[:,1]\n",
    "        plt.scatter(x,y,color=colours[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10428/2090598083.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprediction_tsne_sample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_predictions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtsne_sample\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mground_tsne_sample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_ground\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtsne_sample\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mhard_concept_tsne_sample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_probs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtsne_sample\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplot_tsne_points_with_category\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mposition_tsne_sample\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mprediction_tsne_sample\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_predictions' is not defined"
     ]
    }
   ],
   "source": [
    "if notebook_settings['tsne']:\n",
    "    prediction_tsne_sample = train_predictions[tsne_sample]\n",
    "    ground_tsne_sample = train_ground[tsne_sample]\n",
    "    hard_concept_tsne_sample = train_probs[tsne_sample].argmax(axis=1)\n",
    "\n",
    "    plot_tsne_points_with_category(position_tsne_sample,prediction_tsne_sample)\n",
    "    plot_tsne_points_with_category(position_tsne_sample,ground_tsne_sample)\n",
    "    plot_tsne_points_with_category(position_tsne_sample,hard_concept_tsne_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Concept Completeness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_concept(concept_ids,num_concepts):\n",
    "    one_hot = np.zeros((len(concept_ids),num_concepts))\n",
    "    one_hot[np.arange(len(concept_ids)),concept_ids] = 1\n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/308 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 308/308 [00:40<00:00,  7.58it/s]\n",
      "100%|██████████| 77/77 [00:08<00:00,  9.04it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def concept_vs_prediction(graph,model,gaussian_mixture):\n",
    "    # Get prediction and activation\n",
    "    global raw_activations\n",
    "    raw_activations = torch.zeros(0,model_width)\n",
    "    prediction = model.predict(graph).argmax().item()\n",
    "    # Get the concepts\n",
    "    concept_probs = gaussian_mixture.predict_proba(whiten(raw_activations.detach().numpy()))\n",
    "    return prediction,concept_probs\n",
    "\n",
    "# Takes every observed concept along with the eventual graph prediction and then generates X,Y pairs for training a classifier\n",
    "def generate_concept_to_prediction_map(model,gaussian_mixture,loader,hard=False, ignore_below=0.99):\n",
    "    X = np.zeros((0,num_concepts))\n",
    "    Y = np.zeros(0)\n",
    "    for graph in tqdm(loader):\n",
    "        # assert only one graph in batch\n",
    "        assert graph.batch.max() == 0\n",
    "        prediction,concepts = concept_vs_prediction(graph,model,gaussian_mixture)\n",
    "        if hard:\n",
    "            best_concept = concepts.argmax(axis=1)\n",
    "            concepts = one_hot_concept(best_concept,num_concepts)\n",
    "        concepts = concepts[concepts.max(axis=1) > ignore_below]\n",
    "        X = np.concatenate((X,concepts))\n",
    "        Y = np.concatenate((Y,np.zeros(concepts.shape[0])+prediction))\n",
    "    return X,Y\n",
    "    \n",
    "    \n",
    "X_train,Y_train = generate_concept_to_prediction_map(model,gm,train_loader,True)\n",
    "X_val,Y_val = generate_concept_to_prediction_map(model,gm,val_loader,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Create a decision tree classifier and fit it to the training data\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train,Y_train)\n",
    "\n",
    "\n",
    "# Now clf can be used to make predictions on unseen data\n",
    "# For example, to predict the class of the samples in the test set, you can use:\n",
    "Y_pred = clf.predict(X_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_concept_prediction_prob(concept_id,num_concepts,dt):\n",
    "    # if concept_id is an int, convert to np array\n",
    "    if isinstance(concept_id,int):\n",
    "        concept_id = np.array([concept_id])\n",
    "    # Convert to one hot\n",
    "    one_hot = one_hot_concept(concept_id,num_concepts)\n",
    "    # Predict\n",
    "    return dt.predict_proba(one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For concept id 0, the predictive power is: 45.75\n",
      "For concept id 1, the predictive power is: 94.53\n",
      "For concept id 2, the predictive power is: 49.95\n",
      "For concept id 3, the predictive power is: 56.39\n",
      "For concept id 4, the predictive power is: 67.42\n",
      "For concept id 5, the predictive power is: 55.4\n",
      "For concept id 6, the predictive power is: 80.87\n",
      "For concept id 7, the predictive power is: 84.55\n",
      "For concept id 8, the predictive power is: 54.8\n",
      "For concept id 9, the predictive power is: 75.97\n",
      "For concept id 10, the predictive power is: 48.79\n",
      "For concept id 11, the predictive power is: 82.91\n",
      "For concept id 12, the predictive power is: 53.38\n",
      "For concept id 13, the predictive power is: 54.37\n",
      "For concept id 14, the predictive power is: 66.09\n",
      "For concept id 15, the predictive power is: 50.6\n",
      "For concept id 16, the predictive power is: 57.85\n",
      "For concept id 17, the predictive power is: 32.09\n",
      "For concept id 18, the predictive power is: 91.73\n",
      "For concept id 19, the predictive power is: 83.79\n",
      "For concept id 20, the predictive power is: 62.89\n",
      "For concept id 21, the predictive power is: 37.47\n",
      "For concept id 22, the predictive power is: 56.0\n",
      "For concept id 23, the predictive power is: 71.63\n",
      "For concept id 24, the predictive power is: 66.29\n",
      "For concept id 25, the predictive power is: 57.33\n",
      "For concept id 26, the predictive power is: 84.44\n",
      "For concept id 27, the predictive power is: 87.34\n",
      "For concept id 28, the predictive power is: 89.22\n",
      "For concept id 29, the predictive power is: 89.86\n",
      "For concept id 30, the predictive power is: 43.58\n",
      "For concept id 31, the predictive power is: 55.87\n",
      "For concept id 32, the predictive power is: 88.81\n",
      "For concept id 33, the predictive power is: 55.6\n",
      "For concept id 34, the predictive power is: 51.25\n",
      "For concept id 35, the predictive power is: 51.97\n",
      "For concept id 36, the predictive power is: 71.86\n",
      "For concept id 37, the predictive power is: 43.23\n",
      "For concept id 38, the predictive power is: 50.3\n",
      "For concept id 39, the predictive power is: 79.92\n",
      "For concept id 40, the predictive power is: 45.25\n",
      "For concept id 41, the predictive power is: 51.76\n",
      "For concept id 42, the predictive power is: 46.03\n",
      "For concept id 43, the predictive power is: 66.13\n",
      "For concept id 44, the predictive power is: 44.17\n",
      "For concept id 45, the predictive power is: 100.0\n",
      "For concept id 46, the predictive power is: 73.89\n",
      "For concept id 47, the predictive power is: 65.25\n",
      "For concept id 48, the predictive power is: 57.39\n",
      "For concept id 49, the predictive power is: 86.72\n",
      "For concept id 50, the predictive power is: 88.7\n",
      "For concept id 51, the predictive power is: 92.74\n",
      "For concept id 52, the predictive power is: 70.83\n",
      "For concept id 53, the predictive power is: 46.3\n",
      "For concept id 54, the predictive power is: 60.3\n",
      "For concept id 55, the predictive power is: 59.78\n",
      "For concept id 56, the predictive power is: 61.85\n",
      "For concept id 57, the predictive power is: 40.94\n",
      "For concept id 58, the predictive power is: 65.89\n",
      "For concept id 59, the predictive power is: 86.28\n",
      "For concept id 60, the predictive power is: 94.45\n",
      "For concept id 61, the predictive power is: 68.44\n",
      "For concept id 62, the predictive power is: 87.46\n",
      "For concept id 63, the predictive power is: 60.08\n",
      "Average predictive power:  0.6339604828376829\n"
     ]
    }
   ],
   "source": [
    "# Get prediction from one hot of each concept\n",
    "def print_concept_completeness(concept_id, num_concepts,dt):\n",
    "    probs = get_concept_prediction_prob(concept_id,num_concepts,dt)\n",
    "    # Turn to percentages\n",
    "    probs = (probs*100).round(2).max()\n",
    "    print(f\"For concept id {concept_id}, the predictive power is: {probs}\")\n",
    "    \n",
    "    \n",
    "for i in range(num_concepts):\n",
    "   # print_concept_completeness(i,num_concepts,clf)\n",
    "    pass \n",
    "# Print avergae predictive power\n",
    "print(\"Average predictive power: \",(clf.predict(X_train) == Y_train).sum() / Y_train.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: For a particular graph, what concepts are present, how many times for each, and what is the contribution of that concept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground:  0\n",
      "Prediction:  0 tensor([[0.9620, 0.0097, 0.0182, 0.0101]])\n",
      "Concept vote:  0 [0.52333928 0.08914891 0.27693084 0.11058097]\n"
     ]
    }
   ],
   "source": [
    "def get_concept_distribution_from_graph(graph,model,gaussian_mixture,inclusion_threshold = 0.9):\n",
    "    _,concepts = concept_vs_prediction(graph,model,gaussian_mixture)\n",
    "    \n",
    "    # Count the number of times each concept is present above a certain threshold\n",
    "    most_popular_concept = concepts.argmax(axis=1)\n",
    "    one_hot_concepts = one_hot_concept(most_popular_concept,num_concepts)\n",
    "    \n",
    "    concept_count = np.zeros((num_concepts))\n",
    "    reject_below_threshold = concepts.max(axis=1) > inclusion_threshold\n",
    "    \n",
    "    concept_count = one_hot_concepts*reject_below_threshold.reshape(-1,1)\n",
    "    return concept_count.sum(axis=0)\n",
    "\n",
    "def weighted_predictor(concept_dist,concept_probs):\n",
    "    # Take a weighted sum of the concept_probs with the concept_dist\n",
    "    weighted_sum = concept_probs*concept_dist.reshape(-1,1)\n",
    "    return weighted_sum.sum(axis=0)\n",
    "\n",
    "def sum_predictor(concept_dist,concept_probs):\n",
    "    # If there is a concept present, include its prob\n",
    "    concept_present = concept_dist > 0\n",
    "    concept_probs = concept_probs*concept_present.reshape(-1,1)\n",
    "    # Normalize\n",
    "    return concept_probs.sum(axis=0) / concept_present.sum()\n",
    "\n",
    "    \n",
    "    \n",
    "def concept_vote_graph(graph,model,gaussian_mixture,decision_tree,predictor_rule = weighted_predictor,inclusion_threshold = 0.999):\n",
    "    concept_dist = get_concept_distribution_from_graph(graph,model,gaussian_mixture,inclusion_threshold)\n",
    "    concept_dist = concept_dist / concept_dist.sum()\n",
    "    \n",
    "    # Take a weighted sum of the concept_probs with the concept_dist\n",
    "    concept_probs = get_concept_prediction_prob(np.arange(num_concepts),num_concepts,decision_tree)\n",
    "    \n",
    "    return predictor_rule(concept_dist,concept_probs)\n",
    "    \n",
    "    \n",
    "random_graph_id = np.random.randint(len(val_loader))\n",
    "graph = train_loader.dataset[random_graph_id]\n",
    "graph_ground = graph.y.item()\n",
    "graph_prediction = model.predict_proba(graph)\n",
    "graph_concept_vote = concept_vote_graph(graph,model,gm,clf)\n",
    "\n",
    "print(\"Ground: \",graph_ground)\n",
    "print(\"Prediction: \",graph_prediction.argmax().item(),graph_prediction)\n",
    "print(\"Concept vote: \",graph_concept_vote.argmax(),graph_concept_vote)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Weighted predictor with threshold 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 308/308 [00:39<00:00,  7.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9058441558441559\n",
      "Concept voter accuracy:  0.827922077922078\n",
      "\n",
      "Evaluating Weighted predictor with threshold 0.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 308/308 [00:38<00:00,  8.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9058441558441559\n",
      "Concept voter accuracy:  0.8311688311688312\n",
      "\n",
      "Evaluating Weighted predictor with threshold 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 308/308 [00:40<00:00,  7.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9058441558441559\n",
      "Concept voter accuracy:  0.827922077922078\n",
      "\n",
      "Evaluating Weighted predictor with threshold 0.999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 308/308 [00:39<00:00,  7.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9058441558441559\n",
      "Concept voter accuracy:  0.827922077922078\n",
      "\n",
      "Evaluating Weighted predictor with threshold 0.9999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 308/308 [00:41<00:00,  7.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9058441558441559\n",
      "Concept voter accuracy:  0.827922077922078\n",
      "\n",
      "Evaluating Sum predictor with threshold 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 308/308 [00:39<00:00,  7.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9058441558441559\n",
      "Concept voter accuracy:  0.7337662337662337\n",
      "\n",
      "Evaluating Sum predictor with threshold 0.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 308/308 [00:40<00:00,  7.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9058441558441559\n",
      "Concept voter accuracy:  0.737012987012987\n",
      "\n",
      "Evaluating Sum predictor with threshold 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 308/308 [00:40<00:00,  7.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9058441558441559\n",
      "Concept voter accuracy:  0.75\n",
      "\n",
      "Evaluating Sum predictor with threshold 0.999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 308/308 [00:39<00:00,  7.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9058441558441559\n",
      "Concept voter accuracy:  0.7727272727272727\n",
      "\n",
      "Evaluating Sum predictor with threshold 0.9999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 308/308 [00:38<00:00,  8.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9058441558441559\n",
      "Concept voter accuracy:  0.788961038961039\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Import cross entropy and accuracy\n",
    "from sklearn.metrics import accuracy_score,log_loss\n",
    "\n",
    "# Across a whole dataset, let us evaluate how good the concept_voter is\n",
    "\n",
    "\n",
    "def evaluate_concept_voter(model,gaussian_mixture,decision_tree,loader,predictor_rule = weighted_predictor,inclusion_threshold = 0.999):\n",
    "    # Get the predictions\n",
    "    predictions = np.zeros((0,4))\n",
    "    concept_votes = np.zeros((0,4))\n",
    "    ground = np.zeros((0))\n",
    "    for graph in tqdm(loader):\n",
    "        ground = np.concatenate((ground,graph.y.detach().numpy()))\n",
    "        prediction = model.predict_proba(graph)\n",
    "        concept_vote = concept_vote_graph(graph,model,gaussian_mixture,decision_tree,predictor_rule,inclusion_threshold)\n",
    "        predictions = np.concatenate((predictions,prediction))\n",
    "        concept_votes = np.concatenate((concept_votes,concept_vote.reshape(1,-1)))\n",
    "    \n",
    "    # Caluclate cross entropy loss \n",
    "    print(\"Accuracy: \",accuracy_score(ground,predictions.argmax(axis=1)))\n",
    "    print(\"Concept voter accuracy: \",accuracy_score(ground,concept_votes.argmax(axis=1)))\n",
    "\n",
    "#\n",
    "#for pred_name, predictor in zip([\"Weighted\",\"Sum\"],[weighted_predictor,sum_predictor]):\n",
    "#    for threshold in [0,0.9,0.99,0.999,0.9999]:\n",
    "#        print(f\"Evaluating {pred_name} predictor with threshold {threshold}\")\n",
    "#        evaluate_concept_voter(model,gm,clf,train_loader,predictor,inclusion_threshold=threshold)\n",
    "#        print(\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determine K\n",
    "- Perform GM\n",
    "- Get Concept Completeness\n",
    "- Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### CBE"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e591b006129f0dfb1d51895b4ed619a4625402ac1a377124080c35d47fc6e9a2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
